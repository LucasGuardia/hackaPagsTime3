{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5749c3d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     17\u001b[39m     sys.path.insert(\u001b[32m0\u001b[39m, data_path) \n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ADIÇÃO: Fazemos os imports aqui na Célula 1\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Agora o Python sabe onde encontrar 'data.make_dataset' (dentro de 'src')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmake_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_historical_data, get_metas_from_redshift\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMódulos e funções importados com sucesso.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaiz do projeto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') # Opcional: para limpar os logs\n",
    "\n",
    "# --- Adiciona a pasta 'src' ao path do Python ---\n",
    "project_root = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "# CORREÇÃO: O seu código .py está na pasta 'src', não 'data'\n",
    "data_path = os.path.join(project_root, 'data')\n",
    "\n",
    "# Usamos insert(0, ...) para dar prioridade à pasta 'src'\n",
    "if data_path not in sys.path:\n",
    "    sys.path.insert(0, data_path) \n",
    "# -----------------------------------------------\n",
    "\n",
    "# ADIÇÃO: Fazemos os imports aqui na Célula 1\n",
    "# Agora o Python sabe onde encontrar 'data.make_dataset' (dentro de 'src')\n",
    "from data.make_dataset import get_historical_data, get_metas_from_redshift\n",
    "\n",
    "print(\"Módulos e funções importados com sucesso.\")\n",
    "print(f\"Raiz do projeto: {project_root}\")\n",
    "print(f\"Pasta 'src' priorizada no path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8139c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FASE 1: Coleta de Dados ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_historical_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- FASE 1: Coleta de Dados ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. Busca o histórico de transações (TPV, Margem)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# (Usando a função que já tínhamos)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_historico = \u001b[43mget_historical_data\u001b[49m(dat_start_filter=\u001b[33m'\u001b[39m\u001b[33m2024-01-01\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# Use um período maior\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 2. Busca as Metas de TPV\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# (Usando a nova função que busca do Redshift)\u001b[39;00m\n\u001b[32m      9\u001b[39m df_metas = get_metas_from_redshift()\n",
      "\u001b[31mNameError\u001b[39m: name 'get_historical_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"--- FASE 1: Coleta de Dados ---\")\n",
    "\n",
    "# 1. Busca o histórico de transações (TPV, Margem)\n",
    "# (Usando a função que já tínhamos)\n",
    "df_historico = get_historical_data(dat_start_filter='2024-01-01') # Use um período maior\n",
    "\n",
    "# 2. Busca as Metas de TPV\n",
    "# (Usando a nova função que busca do Redshift)\n",
    "df_metas = get_metas_from_redshift()\n",
    "\n",
    "# 3. Verificações\n",
    "if df_historico is None or df_historico.empty:\n",
    "    print(\"\\n--- ERRO CRÍTICO (FASE 1) ---\")\n",
    "    print(\"A função get_historical_data() falhou ou não retornou dados.\")\n",
    "    print(\"Verifique a conexão e a query em src/data/make_dataset.py\")\n",
    "elif df_metas is None or df_metas.empty:\n",
    "    print(\"\\n--- ERRO CRÍTICO (FASE 1) ---\")\n",
    "    print(\"A função get_metas_from_redshift() falhou ou não retornou dados.\")\n",
    "    print(\"Verifique a query de metas em src/data/make_dataset.py\")\n",
    "else:\n",
    "    print(\"\\n--- SUCESSO (FASE 1) ---\")\n",
    "    print(f\"{len(df_historico)} registros históricos carregados.\")\n",
    "    print(f\"{len(df_metas)} metas de clientes carregadas.\")\n",
    "    \n",
    "    print(\"\\nAmostra dos dados históricos:\")\n",
    "    print(df_historico.head())\n",
    "    \n",
    "    print(\"\\nAmostra das metas:\")\n",
    "    print(df_metas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe25367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- FASE 2: Engenharia de Atributos ---\")\n",
    "\n",
    "# Só executa se ambas as coletas da FASE 1 funcionarem\n",
    "if (df_historico is not None) and (df_metas is not None):\n",
    "    \n",
    "    # Executa a função principal da FASE 2\n",
    "    # Passamos os dados brutos e as metas\n",
    "    df_features = engineer_features(df_historico, df_metas)\n",
    "    \n",
    "    # --- RESULTADO FINAL ---\n",
    "    print(\"\\n--- SUCESSO (FASE 2) ---\")\n",
    "    print(f\"Tabela final criada com {df_features.shape[0]} linhas (clientes) e {df_features.shape[1]} colunas (features).\")\n",
    "    \n",
    "    # Mostra o resultado\n",
    "    print(\"\\nAmostra do DataFrame de Features (Resultado):\")\n",
    "    print(df_features.head())\n",
    "    \n",
    "    # Mostra as colunas criadas\n",
    "    print(\"\\nColunas criadas:\")\n",
    "    print(list(df_features.columns))\n",
    "    \n",
    "    # Salva o DataFrame de features para usar na próxima fase (Treinamento)\n",
    "    # O '..' volta para a raiz do projeto\n",
    "    output_dir = os.path.join(project_root, 'dados', 'processed')\n",
    "    output_path = os.path.join(output_dir, 'features_clientes.csv')\n",
    "    \n",
    "    # Garante que a pasta /dados/processed exista\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    df_features.to_csv(output_path)\n",
    "    print(f\"\\nDataFrame de features salvo em: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- FALHA (FASE 2) ---\")\n",
    "    print(\"A engenharia de atributos foi pulada devido a falhas na FASE 1.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
